from __gin__ import dynamic_registration

import __main__ as eval_script
import seqio
# import bigbench.bbseqio.tasks
from t5.data import mixtures
from t5x import decoding
from t5x import utils
from t5x.contrib.moe import models

include 't5x/contrib/moe/configs/runs/eval.gin'
include 'flaxformer/flaxformer/t5x/configs/moe/models/st_moe_decoder_only_xl.gin'

# Vocabulary (shared by encoder and decoder)
VOCABULARY = @seqio.SentencePieceVocabulary()
seqio.SentencePieceVocabulary.sentencepiece_model_file = "gs://fuzhao/tokenizers/umt5.256000/sentencepiece.model"
seqio.SentencePieceVocabulary.extra_ids = 300

NUM_EMBEDDINGS = 256384  # vocab size rounded to a multiple of 128 for TPU efficiency
CHECKPOINT_PATH = %gin.REQUIRED
EVAL_OUTPUT_DIR = %gin.REQUIRED

USE_CACHED_TASKS = False
NUM_MODEL_PARTITIONS = 8
NUM_EXPERT_PARTITIONS = 32
DROPOUT_RATE = 0.0  # unused boilerplate
MIXTURE_OR_TASK_NAME = "trivia_qa_v010_nocontext"
EVAL_EXPERT_CAPACITY_FACTOR = 2.0

models.MoeDecoderOnlyModel.predict_batch_with_aux.num_decodes = 1
models.MoeDecoderOnlyModel.decode_fn = @decoding.temperature_sample

# decoding.temperature_sample:
#   temperature = 1.0
#   topk = 40

decoding.temperature_sample:
  temperature = 0.0

eval_script.evaluate:
  model = %MODEL  # imported from separate gin file
  dataset_cfg = @utils.DatasetConfig()
  restore_checkpoint_cfg = @utils.RestoreCheckpointConfig()
  output_dir = %EVAL_OUTPUT_DIR

utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME
  task_feature_lengths = None # Auto-computes the max feature lengths.
  split = 'validation'
  batch_size = 16
  shuffle = False
  seed = 42
  use_cached = %USE_CACHED_TASKS

utils.RestoreCheckpointConfig:
  path = %CHECKPOINT_PATH
  mode = 'specific'
